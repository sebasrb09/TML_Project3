{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code can be found here:\n",
    "https://github.com/arezae4/fair-logloss-classification\n",
    "\n",
    "based on this paper: https://arxiv.org/pdf/1903.03910.pdf\n",
    "\n",
    "in-process method that jointly optimizes a fairness transformation and linear feature-based parameters for an exponential family distribution that can be viewed as truncated logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC,abstractmethod\n",
    "from enum import Enum\n",
    "from math import isclose\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_bfgs, minimize\n",
    "import pdb\n",
    "__all__ = ['DP_fair_logloss_classifier','EODD_fair_logloss_classifier','EOPP_fair_logloss_classifier']\n",
    "\n",
    "def _log_logistic(X):\n",
    "    \"\"\" This function is used from scikit-learn source code. Source link below \"\"\"\n",
    "\n",
    "    \"\"\"Compute the log of the logistic function, ``log(1 / (1 + e ** -x))``.\n",
    "    This implementation is numerically stable because it splits positive and\n",
    "    negative values::\n",
    "        -log(1 + exp(-x_i))     if x_i > 0\n",
    "        x_i - log(1 + exp(x_i)) if x_i <= 0\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array-like, shape (M, N)\n",
    "        Argument to the logistic function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: array, shape (M, N)\n",
    "        Log of the logistic function evaluated at every point in x\n",
    "    Notes\n",
    "    -----\n",
    "    Source code at:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/extmath.py\n",
    "    -----\n",
    "\n",
    "    See the blog post describing this implementation:\n",
    "    http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/\n",
    "    \"\"\"\n",
    "    if X.ndim > 1: raise Exception(\"Array of samples cannot be more than 1-D!\")\n",
    "    out = np.empty_like(X) # same dimensions and data types\n",
    "\n",
    "    idx = X>0\n",
    "    out[idx] = -np.log(1.0 + np.exp(-X[idx]))\n",
    "    out[~idx] = X[~idx] - np.log(1.0 + np.exp(X[~idx]))\n",
    "    return out\n",
    "\n",
    "def _dot_intercept(w, X):\n",
    "    \"\"\" This function is used from scikit-learn source code. Source link below \"\"\"\n",
    "\n",
    "    \"\"\"Computes y * np.dot(X, w).\n",
    "    It takes into consideration if the intercept should be fit or not.\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : ndarray, shape (n_features,) or (n_features + 1,)\n",
    "        Coefficient vector.\n",
    "    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Training data.\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Array of labels.\n",
    "    Returns\n",
    "    -------\n",
    "    w : ndarray, shape (n_features,)\n",
    "        Coefficient vector without the intercept weight (w[-1]) if the\n",
    "        intercept should be fit. Unchanged otherwise.\n",
    "    c : float\n",
    "        The intercept.\n",
    "    yz : float\n",
    "        y * np.dot(X, w).\n",
    "    \n",
    "    Notes\n",
    "\t-----\n",
    "\tSource code at:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/linear_model/logistic.py\n",
    "\n",
    "    \"\"\"\n",
    "    c = 0\n",
    "    if w.size == X.shape[1] + 1:\n",
    "        c = w[-1]\n",
    "        w = w[:-1]\n",
    "\n",
    "    z = np.dot(X, w) + c\n",
    "    return z\n",
    "\n",
    "def sum_truncated_loss_grad(theta, X, Y, idx1, idx0, _lambda ):\n",
    "    z = _dot_intercept(theta, X)\n",
    "    p = np.exp(_log_logistic(z))\n",
    "    loss , grad = 0, 0\n",
    "    if _lambda == 0:\n",
    "        loss, grad = sum_logistic_loss_grad(theta,X,Y, np.logical_or(idx1 , idx0))\n",
    "        cond_g1, cond_g0 = idx1, idx0\n",
    "    else:\n",
    "        p1 = np.mean(idx1)   # empirical probability of each group\n",
    "        p0 = np.mean(idx0)\n",
    "        if _lambda > 0:\n",
    "            cond_g1 = np.logical_and( idx1 , p > p1 / _lambda)\n",
    "            cond_g0 = np.logical_and( idx0 , p < (1 - p0 / _lambda))\n",
    "\n",
    "            grad = np.sum(X[np.logical_and(cond_g1, 1 - Y)] ,0) + np.sum(-X[np.logical_and(cond_g0, Y)], 0)\n",
    "            loss = (np.log(_lambda /p1)) * np.sum(cond_g1,0) + np.sum(_dot_intercept(theta,X[cond_g1]) * (1-Y[cond_g1]),0) \\\n",
    "                   + (np.log(_lambda/p0)) * np.sum(cond_g0,0) + np.sum(-_dot_intercept(theta,X[cond_g0]) * Y[cond_g0],0) \n",
    "        else:\n",
    "            cond_g1 = np.logical_and( idx1 , p < (1 + p1 / _lambda))\n",
    "            cond_g0 = np.logical_and( idx0 , p > - p0 / _lambda)\n",
    "\n",
    "            grad = np.sum(X[np.logical_and(cond_g0, 1 - Y)],0) + np.sum(-X[np.logical_and(cond_g1, Y)], 0)\n",
    "            loss = (np.log(-_lambda/p1)) * np.sum(cond_g1,0) + np.sum(-_dot_intercept(theta,X[cond_g1]) * Y[cond_g1],0) \\\n",
    "                   + (np.log(-_lambda/p0)) * np.sum(cond_g0,0) + np.sum(_dot_intercept(theta,X[cond_g0]) * (1-Y[cond_g0]),0) \n",
    "    return loss, grad, np.logical_or(cond_g1, cond_g0)             \n",
    "\n",
    "def sum_logistic_loss_grad(theta, X, Y, idx):\n",
    "    X, Y = X[idx,:], Y[idx]\n",
    "    z = _dot_intercept(theta, X)\n",
    "    p = np.exp(_log_logistic(z))\n",
    "    grad = np.dot(p.T, X) - np.sum(X[Y == 1,:],0)\n",
    "\n",
    "    logZ = z + np.log(1 + np.exp(-z))\n",
    "    loss = np.sum(logZ,0) - np.sum(z * Y,0)\n",
    "    \n",
    "    return loss, grad \n",
    "\n",
    "def fairify(a,b):\n",
    "    avgA, avgB = np.mean(a), np.mean(b)\n",
    "    if a.size == 0:\n",
    "        return np.Inf \n",
    "    elif b.size == 0:\n",
    "        return np.NINF\n",
    "    _lambda = 0\n",
    "    if isclose(avgA,avgB):\n",
    "        return _lambda  # already fair\n",
    "    flipped = False\n",
    "    if avgA < avgB:\n",
    "        b, a = a, b\n",
    "        avgA, avgB = avgB, avgA\n",
    "        flipped = True\n",
    "    diff = avgA - avgB\n",
    "    if diff < 0:\n",
    "        raise ValueError('_lambda is not supposed to be negative')\n",
    "    \n",
    "    a = - np.sort(-a)     # sort descending\n",
    "    b.sort()                 # sort ascending\n",
    "\n",
    "    idxA, idxB = 0, 0   # current index\n",
    "    thrA, thrB = 1.0, 0.0   # current probability threshold\n",
    "    gainA, gainB = 0, 0     # average gain in each group\n",
    "\n",
    "    while True:\n",
    "        if idxA < len(a):\n",
    "            cd_thrA = a[idxA]\n",
    "        else:\n",
    "            cd_thrA = 0.0\n",
    "        cd_thrB_ifA = 1 - (cd_thrA * len(b) / len(a))\n",
    "\n",
    "        if idxB < len(b):\n",
    "            cd_thrB = b[idxB]\n",
    "        else:\n",
    "            cd_thrB = 1.0\n",
    "        \n",
    "        if cd_thrB_ifA <= cd_thrB:\n",
    "            next_thrA = cd_thrA\n",
    "            next_thrB = cd_thrB_ifA\n",
    "        else:\n",
    "            next_thrA = (1 - cd_thrB) * len(a) / len(b)\n",
    "            next_thrB = cd_thrB\n",
    "\n",
    "        next_gainA = gainA + idxA * (thrA - next_thrA) / len(a)\n",
    "        next_gainB = gainB + idxB * (next_thrB - thrB) / len(b)\n",
    "\n",
    "        if isclose(next_gainA + next_gainB , diff):\n",
    "            thrA = next_thrA\n",
    "            _lambda = len(a) / thrA\n",
    "            break\n",
    "        elif next_gainA + next_gainB < diff:\n",
    "            thrA = next_thrA\n",
    "            thrB = next_thrB\n",
    "            if cd_thrB_ifA <= cd_thrB:\n",
    "                idxA += 1\n",
    "            else:\n",
    "                idxB += 1\n",
    "            gainA = next_gainA\n",
    "            gainB = next_gainB\n",
    "        else:\n",
    "            gain_needed = diff - gainA - gainB\n",
    "            _lambda = (idxA + idxB) / (idxA * thrA / len(a) + idxB * (1 - thrB) / len(b) - gain_needed)\n",
    "            break\n",
    "    thrA = len(a) / _lambda\n",
    "    thrB = 1 - len(b) / _lambda\n",
    "    if flipped:\n",
    "        _lambda = -_lambda\n",
    "    avgA = np.mean(np.minimum(a, thrA))\n",
    "    avgB = np.mean(np.maximum(b, thrB))\n",
    "\n",
    "    if not isclose(avgA , avgB):\n",
    "        raise ValueError('Averages not equalized %.3f vs %.3f, diff was %.3f' % (avgA, avgB, diff) )\n",
    "    return _lambda \n",
    "\n",
    "\n",
    "class fair_logloss_classifier:\n",
    "    def __init__(self, tol=1e-6, verbose=True, max_iter=10000, C = .001, random_initialization=False):\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.random_start = random_initialization\n",
    "        self.theta = None\n",
    "        \n",
    "    @abstractmethod\n",
    "    def compute_loss_grad(self, theta,  X, Y):\n",
    "        pass        \n",
    "    @abstractmethod\n",
    "    def _group_protected_attribute(self, Y, A):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,Y,A):\n",
    "        n = np.size(Y)\n",
    "        X = np.hstack((X,np.ones((n,1))))\n",
    "        m = X.shape[1]\n",
    "        \n",
    "        self._group_protected_attribute(Y,A)\n",
    "\n",
    "        if self.random_start:\n",
    "            theta = np.random.random_sample(m) - .5 \n",
    "        else:\n",
    "            theta = np.zeros((m,))\n",
    "        #f = lambda w : self.compute_loss_grad(w,X, Y)[0]\n",
    "        #grad = lambda w : self.compute_loss_grad(w,X, Y)[1] \n",
    "        def callback(w):\n",
    "            f, g = self.compute_loss_grad(w,X,Y)\n",
    "            print(\"fun_value {:.4f} \\t gnorm {:.4f}\".format(f,np.linalg.norm(g)))\n",
    "        #res = fmin_bfgs(f,theta, grad, gtol=self.tol, maxiter=self.max_iter,full_output=False,disp=True, retall=True, callback = callback)\n",
    "        #res = minimize(self.compute_loss_grad, theta,args=(X, Y), method='L-BFGS-B',jac=True, tol=self.tol, options={'maxiter':self.max_iter, 'disp':False}, callback=callback)\n",
    "        res = minimize(self.compute_loss_grad, theta,args=(X, Y), method='L-BFGS-B',jac=True, tol=self.tol, options={'maxiter':self.max_iter, 'disp':self.verbose})\n",
    "         \n",
    "        self.theta = res.x\n",
    "        return self\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_proba_given_y(self,X,Y,A):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def predict_proba(self,X,A):\n",
    "        pass\n",
    "\n",
    "    def _fixed_point_proba(self,X,A):\n",
    "        phat1, pcheck1 = self.predict_proba_given_y(X,np.ones_like(A),A)\n",
    "        phat0, pcheck0 = self.predict_proba_given_y(X,np.zeros_like(A),A)\n",
    "        prob = (phat1 * pcheck0 + phat0 * (1 - pcheck1)) / (1 - pcheck1 + pcheck0)\n",
    "        return prob\n",
    "         \n",
    "    def _predict_proba_given_y(self, X, Y, _lambda, grp1, grp2, p1, p2):\n",
    "        \"\"\"\n",
    "            Computes \\hat{P}(\\hat{Y}|X,A,Y) for two groups\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples,n_features + 1)\n",
    "            Feature vector\n",
    "        Y : ndarray, shape (n_samples,)\n",
    "            Array of labels.\n",
    "        _lambda : float \n",
    "            Fairness parameter for the given two groups\n",
    "        grp1, grp2 : ndarray, shape(n_samples,)\n",
    "            indices for group members\n",
    "        p1, p2, : float\n",
    "            empirical probability of each group from training data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        phat: array, shape (n_samples,) \n",
    "            Prediction probability\n",
    "        pcheck : array, shape (n_samples,)\n",
    "            Adversarial estimation of the empirical distribution\n",
    "        \"\"\"\n",
    "        phat = np.exp(_log_logistic(_dot_intercept(self.theta,X)))\n",
    "        pcheck = np.copy(phat)\n",
    "        \n",
    "        if _lambda > 0:\n",
    "            cond = (p1 / _lambda) < phat\n",
    "            phat[grp1] = np.minimum( phat[grp1] , p1 /_lambda)\n",
    "            pcheck[grp1] = np.where( cond[grp1], np.ones_like(pcheck[grp1]), phat[grp1] * (1 + (_lambda / p1) * (1 - phat[grp1])))\n",
    "            \n",
    "            cond = (1 - (p2 / _lambda)) > phat\n",
    "            phat[grp2] = np.maximum( phat[grp2] , 1 - p2 /_lambda)\n",
    "            pcheck[grp2] = np.where( cond[grp2], np.zeros_like(cond[grp2]), phat[grp2] * (1 - (_lambda / p2) * (1 - phat[grp2])))\n",
    "        elif _lambda < 0:\n",
    "            cond = (1 + (p1 / _lambda)) > phat\n",
    "            phat[grp1] = np.maximum( phat[grp1] , 1 + p1 /_lambda)\n",
    "            pcheck[grp1] = np.where( cond[grp1], np.zeros_like(cond[grp1]), phat[grp1] * (1 - (_lambda / p1) * (1 - phat[grp1])))\n",
    "            \n",
    "            cond = (- p2 / _lambda) < phat\n",
    "            phat[grp2] = np.minimum( phat[grp2] , - p2 /_lambda)\n",
    "            pcheck[grp2] = np.where( cond[grp2], np.ones_like(cond[grp2]), phat[grp2] * (1 + (_lambda / p2) * (1 - phat[grp2])))\n",
    "        return phat, pcheck\n",
    "\n",
    "    def predict(self,X,A):\n",
    "        return np.round(self.predict_proba(X,A))\n",
    "\n",
    "    @abstractmethod\n",
    "    def fairness_violation(self,X,Y,A):\n",
    "        pass\n",
    "    def score(self,X,Y,A):\n",
    "        return 1 - np.mean(abs(self.predict(X,A) - Y))\n",
    "    def expected_error(self,X,Y,A):\n",
    "        proba = self.predict_proba(X,A)\n",
    "        return np.mean(np.where(Y == 1 , 1 - proba, proba))\n",
    "\n",
    "class DP_fair_logloss_classifier(fair_logloss_classifier):\n",
    "    def __init__(self, tol=1e-6, verbose=True, max_iter=10000, C = .1, random_initialization=False):\n",
    "        super().__init__(tol = tol, verbose = verbose, max_iter = max_iter, C = C, random_initialization=random_initialization)\n",
    "\n",
    "    def _group_protected_attribute(self, tr_Y, tr_A):\n",
    "        self.grp1 = tr_A == 1\n",
    "        self.grp2 = tr_A == 0\n",
    "\n",
    "    def compute_loss_grad(self, theta, X, Y):\n",
    "        p = np.exp(_log_logistic(_dot_intercept(theta,X)))\n",
    "        idx1 = self.grp1 # A == 1\n",
    "        idx0 = self.grp2 # A == 0\n",
    "        n = X.shape[0]\n",
    "        self._lambda = fairify(p[idx1], p[idx0]) / n\n",
    "        loss, grad, trunc_idx = sum_truncated_loss_grad(theta, X, Y, idx1, idx0, self._lambda)\n",
    "        loss_ow, grad_ow = sum_logistic_loss_grad(theta,X,Y, np.logical_not(trunc_idx))\n",
    "\n",
    "        loss += loss_ow\n",
    "        grad += grad_ow\n",
    "        \n",
    "        loss = loss / n + .5 * self.C * np.dot(theta, theta)\n",
    "        grad = grad / n + self.C * theta\n",
    "        return loss, grad\n",
    "    \n",
    "    def predict_proba_given_y(self,X,Y,A):\n",
    "        grp1 = A == 1\n",
    "        grp2 = A == 0\n",
    "        p1, p2 = np.mean(self.grp1) , np.mean(self.grp2) # group empirical probability based on training data\n",
    "        \n",
    "        return self._predict_proba_given_y(X,Y, self._lambda, grp1, grp2, p1, p2)\n",
    "                   \n",
    "    def predict_proba(self,X,A):\n",
    "        return self.predict_proba_given_y(X,np.empty_like(A),A)[0]\n",
    "\n",
    "    def fairness_violation(self,X,Y,A):\n",
    "        proba = self.predict_proba(X,A)\n",
    "        return abs(np.mean(proba[A == 1]) - np.mean(proba[A == 0]))\n",
    "\n",
    "\n",
    "class EOPP_fair_logloss_classifier(fair_logloss_classifier):\n",
    "    def __init__(self, tol=1e-6, verbose=True, max_iter=10000, C = .1, random_initialization=False):\n",
    "        super().__init__(tol = tol, verbose = verbose, max_iter = max_iter, C = C, random_initialization= random_initialization)\n",
    "\n",
    "    def _group_protected_attribute(self, tr_Y, tr_A):\n",
    "        self.grp1 = np.logical_and( tr_A == 1, tr_Y == 1)\n",
    "        self.grp2 = np.logical_and( tr_A == 0, tr_Y == 1)\n",
    "\n",
    "    def compute_loss_grad(self, theta, X, Y):\n",
    "        p = np.exp(_log_logistic(_dot_intercept(theta,X)))\n",
    "        idx1 = self.grp1 # np.logical_and(A == 1, Y == 1)\n",
    "        idx0 = self.grp2 # np.logical_and(A == 0, Y == 1)\n",
    "        n = X.shape[0]\n",
    "        self._lambda = fairify(p[idx1], p[idx0]) / n \n",
    "        loss, grad, trunc_idx  = sum_truncated_loss_grad(theta, X, Y, idx1, idx0, self._lambda)\n",
    "        loss_ow, grad_ow = sum_logistic_loss_grad(theta,X,Y, np.logical_not(trunc_idx))\n",
    "\n",
    "        loss += loss_ow\n",
    "        grad += grad_ow\n",
    "        loss = loss / n + .5 * self.C * np.dot(theta, theta)\n",
    "        grad = grad /n + self.C * theta\n",
    "        return loss, grad\n",
    "\n",
    "    def predict_proba_given_y(self,X,Y,A):\n",
    "        grp1 = np.logical_and(A == 1, Y == 1)\n",
    "        grp2 = np.logical_and(A == 0, Y == 1)\n",
    "        p1, p2 = np.mean(self.grp1) , np.mean(self.grp2)\n",
    "        return self._predict_proba_given_y(X,Y, self._lambda, grp1, grp2, p1, p2)\n",
    "        \n",
    "            \n",
    "    def predict_proba(self,X,A):\n",
    "        return self._fixed_point_proba(X,A)\n",
    "\n",
    "    def fairness_violation(self,X,Y,A):\n",
    "        proba = self.predict_proba(X,A)\n",
    "        return abs(np.mean(proba[np.logical_and(Y == 1, A == 1)]) - np.mean(proba[np.logical_and(Y == 1, A == 0)]))  \n",
    "    \n",
    "\n",
    "class EODD_fair_logloss_classifier(fair_logloss_classifier):\n",
    "    def __init__(self, tol=1e-6, verbose=True, max_iter=10000, C = .1, random_initialization=False):\n",
    "        super().__init__(tol = tol, verbose = verbose, max_iter = max_iter, C = C, random_initialization=random_initialization)\n",
    "\n",
    "    def _group_protected_attribute(self, tr_Y, tr_A):\n",
    "        self.grp1 = np.logical_and( tr_A == 1, tr_Y == 1)\n",
    "        self.grp2 = np.logical_and( tr_A == 0, tr_Y == 1)\n",
    "        self.grp3 = np.logical_and( tr_A == 1, tr_Y == 0)\n",
    "        self.grp4 = np.logical_and( tr_A == 0, tr_Y == 0)\n",
    "         \n",
    "    def compute_loss_grad(self, theta,X, Y):\n",
    "        p = np.exp(_log_logistic(_dot_intercept(theta,X)))\n",
    "        n = X.shape[0]\n",
    "        idx11 = self.grp1 # np.logical_and(A == 1, Y == 1)\n",
    "        idx01 = self.grp2 # np.logical_and(A == 0, Y == 1)\n",
    "        self._lambda1 = fairify(p[idx11], p[idx01]) / n \n",
    "\n",
    "        loss1, grad1, trunc_idx1 = sum_truncated_loss_grad(theta, X, Y, idx11, idx01, self._lambda1)\n",
    "\n",
    "        idx10 = self.grp3 # np.logical_and(A == 1, Y == 0)\n",
    "        idx00 = self.grp4 # np.logical_and(A == 0, Y == 0)\n",
    "        self._lambda0 = fairify(p[idx10], p[idx00]) / n \n",
    "\n",
    "        loss0, grad0, trunc_idx2 = sum_truncated_loss_grad(theta, X, Y, idx10, idx00, self._lambda0)\n",
    "        \n",
    "        loss_ow, grad_ow = sum_logistic_loss_grad(theta, X, Y, np.logical_not(np.logical_or(trunc_idx1, trunc_idx2)))\n",
    "\n",
    "        loss = loss1 + loss0 + loss_ow\n",
    "        grad = grad1 + grad0 + grad_ow\n",
    "        loss = loss / n + .5 * self.C * np.dot(theta, theta)\n",
    "        grad = grad /n + self.C * theta\n",
    "        #pdb.set_trace()\n",
    "        return loss, grad    \n",
    "    \n",
    "    def predict_proba_given_y(self,X,Y,A):\n",
    "        grp1 = np.logical_and(A == 1, Y == 1)\n",
    "        grp2 = np.logical_and(A == 0, Y == 1)\n",
    "        p1, p2 = np.mean(self.grp1) , np.mean(self.grp2)\n",
    "        phat, pcheck = self._predict_proba_given_y(X, Y, self._lambda1, grp1, grp2, p1, p2)\n",
    "        \n",
    "        grp3 = np.logical_and(A == 1, Y == 0)\n",
    "        grp4 = np.logical_and(A == 0, Y == 0)\n",
    "        p3, p4 = np.mean(self.grp3) , np.mean(self.grp4)\n",
    "        phat_, pcheck_ = self._predict_proba_given_y(X, Y, self._lambda0, grp3, grp4, p3, p4)\n",
    "        idx = np.logical_or(grp3, grp4)\n",
    "        phat[idx], pcheck[idx] = phat_[idx], pcheck_[idx]\n",
    "\n",
    "        return phat, pcheck\n",
    "        \n",
    "\n",
    "    def predict_proba(self,X,A):\n",
    "        return self._fixed_point_proba(X,A)\n",
    "        \n",
    "    def fairness_violation(self,X,Y,A):\n",
    "        proba = self.predict_proba(X,A)\n",
    "        return  abs(np.mean(proba[np.logical_and(Y == 1, A == 1)]) - np.mean(proba[np.logical_and(Y == 1, A == 0)]))  \\\n",
    "            +   abs(np.mean(proba[np.logical_and(Y == 0, A == 1)]) - np.mean(proba[np.logical_and(Y == 0, A == 0)]))\n",
    "   \n",
    "     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_IBM_adult():\n",
    "    dataA = pd.read_csv('../data/IBM_adult_A.csv',sep='\\t',index_col = 0,header=None)#,usecols=range(1,2))\n",
    "    dataY = pd.read_csv('../data/IBM_adult_Y.csv',sep='\\t',index_col = 0,header=None)#,usecols=range(0,2))\n",
    "    dataX = pd.read_csv('../data/IBM_adult_X.csv',sep='\\t',index_col = 0)\n",
    "    perm = np.genfromtxt('../data/adult_perm.csv', delimiter=',')\n",
    "    return dataA.iloc[:,0],dataY.iloc[:,0],dataX,perm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 1 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.282 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.159 \t expected_err : 0.284 \t fair_violation : 0.006 \n",
      "accuracy: 0.84145352694037\n",
      "C = 0.9465246554138719\n",
      "False Negative Rate total fair: 0.4482453553524034, for males: 0.44459738472126636, and for females: 0.47010309278350515\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8438858996093462\n",
      "C = 0.9390285250976634\n",
      "False Negative Rate total: 0.4093187850191684, for males: 0.39298004129387476, and for females: 0.5072164948453608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 2 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.289 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.152 \t expected_err : 0.288 \t fair_violation : 0.002 \n",
      "accuracy: 0.8478661457949436\n",
      "C = 0.9475418294390802\n",
      "False Negative Rate total fair: 0.4263943919536727, for males: 0.4208096590909091, and for females: 0.46021505376344085\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.850372226726616\n",
      "C = 0.9393896955848751\n",
      "False Negative Rate total: 0.3940871685461749, for males: 0.3817471590909091, and for females: 0.46881720430107526\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 3 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.279 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.280 \t fair_violation : 0.003 \n",
      "accuracy: 0.8437384830839537\n",
      "C = 0.9408564900125304\n",
      "False Negative Rate total fair: 0.42043751872939766, for males: 0.42421015264465745, and for females: 0.4\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8463919805410186\n",
      "C = 0.9366108940812266\n",
      "False Negative Rate total: 0.3928678453700929, for males: 0.3801916932907348, and for females: 0.46153846153846156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 4 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.282 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.282 \t fair_violation : 0.008 \n",
      "accuracy: 0.8439596078720425\n",
      "C = 0.943399425075551\n",
      "False Negative Rate total fair: 0.4465844116761962, for males: 0.45319675026492406, and for females: 0.40853658536585363\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8470553549052848\n",
      "C = 0.9393159873221788\n",
      "False Negative Rate total: 0.399939813421607, for males: 0.39279406570116565, and for females: 0.4410569105691057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 5 ----------------------------------\n",
      "Train - predict_err : 0.153 \t expected_err : 0.282 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.158 \t expected_err : 0.284 \t fair_violation : 0.003 \n",
      "accuracy: 0.8416746517284588\n",
      "C = 0.9430677378934178\n",
      "False Negative Rate total fair: 0.41788812443912654, for males: 0.41471103327495623, and for females: 0.4364754098360656\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8427065674062062\n",
      "C = 0.934539691899462\n",
      "False Negative Rate total: 0.39126533054142987, for males: 0.37583187390542905, and for females: 0.48155737704918034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 6 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.288 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.152 \t expected_err : 0.286 \t fair_violation : 0.006 \n",
      "accuracy: 0.8478661457949436\n",
      "C = 0.9453084690793838\n",
      "False Negative Rate total fair: 0.4158682634730539, for males: 0.4114081996434938, and for females: 0.4392523364485981\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8468342301171962\n",
      "C = 0.9396624161568512\n",
      "False Negative Rate total: 0.3991017964071856, for males: 0.3775401069518717, and for females: 0.5121495327102804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 7 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.286 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.287 \t fair_violation : 0.000 \n",
      "accuracy: 0.8466131053291074\n",
      "C = 0.9424928134443871\n",
      "False Negative Rate total fair: 0.41612522150029535, for males: 0.4128214159915463, and for females: 0.43327239488117003\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8500036854131348\n",
      "C = 0.9374880224073119\n",
      "False Negative Rate total: 0.37950383933845244, for males: 0.35963367382881295, and for females: 0.4826325411334552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 8 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.288 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.285 \t fair_violation : 0.008 \n",
      "accuracy: 0.8471290631679811\n",
      "C = 0.9509250386968379\n",
      "False Negative Rate total fair: 0.4289544235924933, for males: 0.4258474576271186, and for females: 0.44571428571428573\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8491191862607799\n",
      "C = 0.9418957765165475\n",
      "False Negative Rate total: 0.4009532320524278, for males: 0.3866525423728814, and for females: 0.4780952380952381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 9 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.281 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.280 \t fair_violation : 0.003 \n",
      "accuracy: 0.8458760227021449\n",
      "C = 0.94145352694037\n",
      "False Negative Rate total fair: 0.4024683925346177, for males: 0.39864864864864863, and for females: 0.4235294117647059\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8479398540576398\n",
      "C = 0.9366551190388442\n",
      "False Negative Rate total: 0.3798916315472607, for males: 0.3630867709815078, and for females: 0.4725490196078431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 10 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.274 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.162 \t expected_err : 0.277 \t fair_violation : 0.006 \n",
      "accuracy: 0.8381366551190389\n",
      "C = 0.9494582442691826\n",
      "False Negative Rate total fair: 0.44487485101311086, for males: 0.4472954230235784, and for females: 0.4300847457627119\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8445492739736125\n",
      "C = 0.9402668239109604\n",
      "False Negative Rate total: 0.4028605482717521, for males: 0.3907766990291262, and for females: 0.4766949152542373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 11 ----------------------------------\n",
      "Train - predict_err : 0.157 \t expected_err : 0.277 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.274 \t fair_violation : 0.007 \n",
      "accuracy: 0.8472764796933736\n",
      "C = 0.9475713127441586\n",
      "False Negative Rate total fair: 0.42781534842693325, for males: 0.4224819525610175, and for females: 0.45934959349593496\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8504459349893123\n",
      "C = 0.9394781455001106\n",
      "False Negative Rate total: 0.37959423698912087, for males: 0.36094877964936406, and for females: 0.4898373983739837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 12 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.281 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.282 \t fair_violation : 0.002 \n",
      "accuracy: 0.8439596078720425\n",
      "C = 0.946974275816319\n",
      "False Negative Rate total fair: 0.4470764617691154, for males: 0.44672701949860727, and for females: 0.44924406047516197\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8483083953711211\n",
      "C = 0.9399646200339058\n",
      "False Negative Rate total: 0.4047976011994003, for males: 0.3906685236768802, and for females: 0.4924406047516199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 13 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.283 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.286 \t fair_violation : 0.006 \n",
      "accuracy: 0.8449178152870936\n",
      "C = 0.9474165253924965\n",
      "False Negative Rate total fair: 0.4289871944121071, for males: 0.4219337205329689, and for females: 0.46954813359528486\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8469816466425887\n",
      "C = 0.9388147711358443\n",
      "False Negative Rate total: 0.39726426076833526, for males: 0.38435257943286644, and for females: 0.4715127701375246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 14 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.277 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.157 \t expected_err : 0.280 \t fair_violation : 0.005 \n",
      "accuracy: 0.8427802756689025\n",
      "C = 0.9439448662195032\n",
      "False Negative Rate total fair: 0.43717277486910994, for males: 0.43555555555555553, and for females: 0.44639376218323584\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8457286061767524\n",
      "C = 0.9385494213901379\n",
      "False Negative Rate total: 0.4098312972658522, for males: 0.39179487179487177, and for females: 0.5126705653021443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 15 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.283 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.284 \t fair_violation : 0.003 \n",
      "accuracy: 0.8461708557529299\n",
      "C = 0.9448735903294759\n",
      "False Negative Rate total fair: 0.41114058355437666, for males: 0.40704569236135335, and for females: 0.43346007604562736\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8475713127441586\n",
      "C = 0.9387410628731481\n",
      "False Negative Rate total: 0.3775419982316534, for males: 0.35856295779560515, and for females: 0.48098859315589354\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 16 ----------------------------------\n",
      "Train - predict_err : 0.159 \t expected_err : 0.278 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.276 \t fair_violation : 0.008 \n",
      "accuracy: 0.8466131053291074\n",
      "C = 0.9440701702660869\n",
      "False Negative Rate total fair: 0.4401064773735581, for males: 0.4513986013986014, and for females: 0.3781190019193858\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8501511019385273\n",
      "C = 0.9400235866440628\n",
      "False Negative Rate total: 0.3904170363797693, for males: 0.3758741258741259, and for females: 0.47024952015355087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 17 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.286 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.287 \t fair_violation : 0.001 \n",
      "accuracy: 0.8443281491855237\n",
      "C = 0.9454264022996978\n",
      "False Negative Rate total fair: 0.4300088783663806, for males: 0.42110726643598617, and for females: 0.48261758691206547\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8460971474902337\n",
      "C = 0.9390580084027419\n",
      "False Negative Rate total: 0.4030778336786031, for males: 0.3837370242214533, and for females: 0.5173824130879345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 18 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.286 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.152 \t expected_err : 0.284 \t fair_violation : 0.002 \n",
      "accuracy: 0.8477924375322473\n",
      "C = 0.9501732144173362\n",
      "False Negative Rate total fair: 0.42748091603053434, for males: 0.42046641141663765, and for females: 0.4652908067542214\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8506670597774011\n",
      "C = 0.9424191051816909\n",
      "False Negative Rate total: 0.399588960657663, for males: 0.3825269752871563, and for females: 0.4915572232645403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 19 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.285 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.285 \t fair_violation : 0.001 \n",
      "accuracy: 0.8466868135918036\n",
      "C = 0.9508513304341417\n",
      "False Negative Rate total fair: 0.44424620874219445, for males: 0.4397778549114891, and for females: 0.470954356846473\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8487506449472986\n",
      "C = 0.9401783739957249\n",
      "False Negative Rate total: 0.39250669045495096, for males: 0.383547379382159, and for females: 0.4460580912863071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 20 ----------------------------------\n",
      "Train - predict_err : 0.153 \t expected_err : 0.282 \t fair_violation : 0.000 \n",
      "Test  - predict_err : 0.163 \t expected_err : 0.287 \t fair_violation : 0.005 \n",
      "accuracy: 0.8365887816024177\n",
      "C = 0.9445566447998821\n",
      "False Negative Rate total fair: 0.44738389182833627, for males: 0.446873932353946, and for females: 0.45052631578947366\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.842927692194295\n",
      "C = 0.9353136286577726\n",
      "False Negative Rate total: 0.40652557319223986, for males: 0.3969935087119918, and for females: 0.4652631578947368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import arff\n",
    "# from prepare_data import prepare_compas,prepare_IBM_adult, prepare_law\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# from fair_logloss import DP_fair_logloss_classifier, EOPP_fair_logloss_classifier, EODD_fair_logloss_classifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def compute_error(Yhat,proba,Y):\n",
    "    err = 1 - np.sum(Yhat == Y) / Y.shape[0] \n",
    "    exp_zeroone = np.mean(np.where(Y == 1 , 1 - proba, proba))\n",
    "    return err, exp_zeroone\n",
    "\n",
    "def confu_metrics(confusion_m):\n",
    "    #Confusion Matrix\n",
    "    TN, FP, FN, TP = confusion_m.ravel()\n",
    "    \n",
    "    N = TP+FP+FN+TN #Total population\n",
    "    ACC = (TP+TN)/N #Accuracy\n",
    "    TPR = TP/(TP+FN) # True positive rate\n",
    "    FPR = FP/(FP+TN) # False positive rate\n",
    "    FNR = FN/(TP+FN) # False negative rate\n",
    "    PPP = (TP + FP)/N # % predicted as positive\n",
    "    \n",
    "    return FNR\n",
    "\n",
    "def fairness_metrics(y_true,y_pred,A):\n",
    "    \"\"\"Calculate fairness for subgroup of population\"\"\"\n",
    "    A.reset_index(inplace=True,drop = True)\n",
    "    ind_m = A[A==1].index.tolist()\n",
    "    ind_f = A[A==0].index.tolist()\n",
    "    \n",
    "    ind_m = [int(i) for i in ind_m]\n",
    "    ind_f = [int(i) for i in ind_f]\n",
    "    \n",
    "    cm_m = confusion_matrix(y_true[ind_m],y_pred[ind_m])\n",
    "    cm_f = confusion_matrix(y_true[ind_f],y_pred[ind_f])\n",
    "    FNR = confu_metrics(confusion_matrix(y_true,y_pred))\n",
    "    FNR_m = confu_metrics(cm_m)\n",
    "    FNR_f = confu_metrics(cm_f)\n",
    "    \n",
    "    return FNR,FNR_m,FNR_f\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataA,dataY,dataX,perm = prepare_IBM_adult()\n",
    "    dataset = \"adult\"\n",
    "    C = .005\n",
    "    criteria = 'dp'#sys.argv[2]\n",
    "    if criteria == 'dp':\n",
    "        h = DP_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)\n",
    "    elif criteria == 'eqopp':\n",
    "        h = EOPP_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)\n",
    "    elif criteria == 'eqodd':\n",
    "        h = EODD_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)    \n",
    "    else:\n",
    "        raise ValueError('Invalid second arg')\n",
    "    filename_tr = \"fairll_{}_{:.3f}_{}_tr.csv\".format(dataset,C,criteria)\n",
    "    filename_ts = \"fairll_{}_{:.3f}_{}_ts.csv\".format(dataset,C,criteria)\n",
    "    \n",
    "    # outfile_tr = open(filename_tr,\"w\")\n",
    "    # outfile_ts = open(filename_ts,\"w\")\n",
    "\n",
    "    for r in range(20):\n",
    "        order = perm[r,:]\n",
    "        tr_sz = int(np.floor(.7 * dataX.shape[0]))\n",
    "        tr_idx = order[:tr_sz]\n",
    "        ts_idx = order[tr_sz:]\n",
    "        tr_X = dataX.reindex(tr_idx)\n",
    "        ts_X = dataX.reindex(ts_idx)\n",
    "        \n",
    "        tr_A = dataA.reindex(tr_X.index)\n",
    "        ts_A = dataA.reindex(ts_X.index)\n",
    "        tr_Y = dataY.reindex(tr_X.index)\n",
    "        ts_Y = dataY.reindex(ts_X.index)\n",
    "        \n",
    "        # Comment out to not include A in features\n",
    "        tr_X = pd.concat([tr_X, tr_A], axis=1) \n",
    "        ts_X = pd.concat([ts_X, ts_A], axis=1)\n",
    "        # ---------\n",
    "\n",
    "        for c in list(tr_X.columns):\n",
    "            if tr_X[c].min() < 0 or tr_X[c].max() > 1:\n",
    "                mu = tr_X[c].mean()\n",
    "                s = tr_X[c].std(ddof=0)\n",
    "                tr_X.loc[:,c] = (tr_X[c] - mu) / s\n",
    "                ts_X.loc[:,c] = (ts_X[c] - mu) / s\n",
    "        \n",
    "        h.fit(tr_X.values,tr_Y.values,tr_A.values)\n",
    "        exp_zo_tr = h.expected_error(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        exp_zo_ts = h.expected_error(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        err_tr = 1 - h.score(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        err_ts = 1 - h.score(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        violation_tr = h.fairness_violation(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        violation_ts = h.fairness_violation(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        prediction = h.predict(ts_X.values, ts_A.values)\n",
    "\n",
    "        # calculate consistency measure \n",
    "        # we use sklearn to find the nearest neighbors\n",
    "        neigh = NearestNeighbors(n_neighbors=11) # the first neighbour is always the data itself, therefore take 11 neighbours\n",
    "        nbrs = neigh.fit(ts_X.values)\n",
    "        distances, indices = nbrs.kneighbors(ts_X.values)\n",
    "        # calculate C\n",
    "        sum = 0\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(11):\n",
    "                sum += np.abs(int(prediction[i])-int(prediction[indices[i][j]]))\n",
    "        result = 1 - sum*(1/(10*len(indices)))\n",
    "        \n",
    "        total_FNR_fair,m_FNR_fair,f_FNR_fair = fairness_metrics(ts_Y.values,prediction,ts_A)\n",
    "        \n",
    "        \n",
    "        # train logistic regression \n",
    "        clf = LogisticRegression(random_state=0).fit(tr_X.values, tr_Y.values)\n",
    "        logistic_prediction = clf.predict(ts_X.values)\n",
    "        # calculate C\n",
    "        sum = 0\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(11):\n",
    "                sum += np.abs(int(logistic_prediction[i])-int(logistic_prediction[indices[i][j]]))\n",
    "        result_logistic_regression = 1 - sum*(1/(10*len(indices)))\n",
    "        \n",
    "        total_FNR,m_FNR,f_FNR = fairness_metrics(ts_Y.values,logistic_prediction,ts_A)\n",
    "        \n",
    "        print(\"---------------------------- Random Split %d ----------------------------------\" % (r + 1))\n",
    "        print(\"Train - predict_err : {:.3f} \\t expected_err : {:.3f} \\t fair_violation : {:.3f} \".format(err_tr, exp_zo_tr,violation_tr))\n",
    "        print(\"Test  - predict_err : {:.3f} \\t expected_err : {:.3f} \\t fair_violation : {:.3f} \".format(err_ts, exp_zo_ts,violation_ts))\n",
    "        print(\"accuracy:\", accuracy_score(ts_Y.values, prediction))\n",
    "        print(\"C =\",result)\n",
    "        print(\"False Negative Rate total fair: {}, for males: {}, and for females: {}\".format(total_FNR_fair,m_FNR_fair,f_FNR_fair))\n",
    "        print(\"for non-fair logistic regression:\")\n",
    "        print(\"accuracy:\", accuracy_score(ts_Y.values, logistic_prediction))\n",
    "        print(\"C =\",result_logistic_regression)\n",
    "        print(\"False Negative Rate total: {}, for males: {}, and for females: {}\".format(total_FNR,m_FNR,f_FNR))\n",
    "        print(\"\")\n",
    "\n",
    "    #     outfile_ts.write(\"{:.4f},{:.4f},{:.4f}\\n\".format(exp_zo_ts,err_ts, violation_ts))\n",
    "    #     outfile_tr.write(\"{:.4f},{:.4f},{:.4f}\\n\".format(exp_zo_tr,err_tr, violation_tr))\n",
    "        \n",
    "    # outfile_tr.close()\n",
    "    # outfile_ts.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C increases by using the fair logistic regression version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 1 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.231 \t fair_violation : 0.063 \n",
      "Test  - predict_err : 0.157 \t expected_err : 0.233 \t fair_violation : 0.070 \n",
      "accuracy: 0.8426328591435099\n",
      "C = 0.9512862091840495\n",
      "False Negative Rate total fair: 0.4473606605721026, for males: 0.42980041293874743, and for females: 0.5525773195876289\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8438858996093462\n",
      "C = 0.9390285250976634\n",
      "False Negative Rate total: 0.4093187850191684, for males: 0.39298004129387476, and for females: 0.5072164948453608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 2 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.233 \t fair_violation : 0.061 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.231 \t fair_violation : 0.058 \n",
      "accuracy: 0.8472764796933736\n",
      "C = 0.949215007002285\n",
      "False Negative Rate total fair: 0.4221274001828711, for males: 0.40767045454545453, and for females: 0.5096774193548387\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.850372226726616\n",
      "C = 0.9393896955848751\n",
      "False Negative Rate total: 0.3940871685461749, for males: 0.3817471590909091, and for females: 0.46881720430107526\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 3 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.232 \t fair_violation : 0.060 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.233 \t fair_violation : 0.055 \n",
      "accuracy: 0.8444755657109162\n",
      "C = 0.9469226800324316\n",
      "False Negative Rate total fair: 0.42193587054240334, for males: 0.4096556620518282, and for females: 0.48846153846153845\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8463919805410186\n",
      "C = 0.9366108940812266\n",
      "False Negative Rate total: 0.3928678453700929, for males: 0.3801916932907348, and for females: 0.46153846153846156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 4 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.233 \t fair_violation : 0.067 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.234 \t fair_violation : 0.031 \n",
      "accuracy: 0.8438858996093462\n",
      "C = 0.9490233655192747\n",
      "False Negative Rate total fair: 0.4297321697261511, for males: 0.4206993995054751, and for females: 0.4817073170731707\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8470553549052848\n",
      "C = 0.9393159873221788\n",
      "False Negative Rate total: 0.399939813421607, for males: 0.39279406570116565, and for females: 0.4410569105691057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 5 ----------------------------------\n",
      "Train - predict_err : 0.153 \t expected_err : 0.230 \t fair_violation : 0.061 \n",
      "Test  - predict_err : 0.160 \t expected_err : 0.233 \t fair_violation : 0.072 \n",
      "accuracy: 0.8404953195253188\n",
      "C = 0.9479251124051006\n",
      "False Negative Rate total fair: 0.4313490876458271, for males: 0.415061295971979, and for females: 0.5266393442622951\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8427065674062062\n",
      "C = 0.934539691899462\n",
      "False Negative Rate total: 0.39126533054142987, for males: 0.37583187390542905, and for females: 0.48155737704918034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 6 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.233 \t fair_violation : 0.069 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.232 \t fair_violation : 0.079 \n",
      "accuracy: 0.8454337731259675\n",
      "C = 0.9517947961966536\n",
      "False Negative Rate total fair: 0.429940119760479, for males: 0.40606060606060607, and for females: 0.5551401869158878\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8468342301171962\n",
      "C = 0.9396624161568512\n",
      "False Negative Rate total: 0.3991017964071856, for males: 0.3775401069518717, and for females: 0.5121495327102804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 7 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.232 \t fair_violation : 0.068 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.233 \t fair_violation : 0.069 \n",
      "accuracy: 0.8460234392275374\n",
      "C = 0.9495393233581484\n",
      "False Negative Rate total fair: 0.41966922622563496, for males: 0.39908418457203243, and for females: 0.526508226691042\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8500036854131348\n",
      "C = 0.9374880224073119\n",
      "False Negative Rate total: 0.37950383933845244, for males: 0.35963367382881295, and for females: 0.4826325411334552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 8 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.234 \t fair_violation : 0.065 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.230 \t fair_violation : 0.044 \n",
      "accuracy: 0.8460234392275374\n",
      "C = 0.9527677452642441\n",
      "False Negative Rate total fair: 0.43372058385463214, for males: 0.4226694915254237, and for females: 0.49333333333333335\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8491191862607799\n",
      "C = 0.9418957765165475\n",
      "False Negative Rate total: 0.4009532320524278, for males: 0.3866525423728814, and for females: 0.4780952380952381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 9 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.233 \t fair_violation : 0.065 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.233 \t fair_violation : 0.058 \n",
      "accuracy: 0.8454337731259675\n",
      "C = 0.9472543672145648\n",
      "False Negative Rate total fair: 0.4114990969295605, for males: 0.3915362731152205, and for females: 0.5215686274509804\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8479398540576398\n",
      "C = 0.9366551190388442\n",
      "False Negative Rate total: 0.3798916315472607, for males: 0.3630867709815078, and for females: 0.4725490196078431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 10 ----------------------------------\n",
      "Train - predict_err : 0.153 \t expected_err : 0.231 \t fair_violation : 0.061 \n",
      "Test  - predict_err : 0.160 \t expected_err : 0.234 \t fair_violation : 0.060 \n",
      "accuracy: 0.8404953195253188\n",
      "C = 0.9499447188029778\n",
      "False Negative Rate total fair: 0.4359356376638856, for males: 0.4223300970873786, and for females: 0.5190677966101694\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8445492739736125\n",
      "C = 0.9402668239109604\n",
      "False Negative Rate total: 0.4028605482717521, for males: 0.3907766990291262, and for females: 0.4766949152542373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 11 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.233 \t fair_violation : 0.057 \n",
      "Test  - predict_err : 0.151 \t expected_err : 0.231 \t fair_violation : 0.081 \n",
      "accuracy: 0.8486769366846023\n",
      "C = 0.9512935800103192\n",
      "False Negative Rate total fair: 0.40958541605410176, for males: 0.38982468202131315, and for females: 0.5264227642276422\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8504459349893123\n",
      "C = 0.9394781455001106\n",
      "False Negative Rate total: 0.37959423698912087, for males: 0.36094877964936406, and for females: 0.4898373983739837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 12 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.232 \t fair_violation : 0.059 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.233 \t fair_violation : 0.051 \n",
      "accuracy: 0.8452863566005749\n",
      "C = 0.9506375764723225\n",
      "False Negative Rate total fair: 0.4371814092953523, for males: 0.4244428969359331, and for females: 0.5161987041036717\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8483083953711211\n",
      "C = 0.9399646200339058\n",
      "False Negative Rate total: 0.4047976011994003, for males: 0.3906685236768802, and for females: 0.4924406047516199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 13 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.232 \t fair_violation : 0.066 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.233 \t fair_violation : 0.051 \n",
      "accuracy: 0.8452126483378787\n",
      "C = 0.9503648559003465\n",
      "False Negative Rate total fair: 0.4243306169965076, for males: 0.4079262043047489, and for females: 0.518664047151277\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8469816466425887\n",
      "C = 0.9388147711358443\n",
      "False Negative Rate total: 0.39726426076833526, for males: 0.38435257943286644, and for females: 0.4715127701375246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 14 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.232 \t fair_violation : 0.068 \n",
      "Test  - predict_err : 0.159 \t expected_err : 0.233 \t fair_violation : 0.065 \n",
      "accuracy: 0.84145352694037\n",
      "C = 0.9475492002653497\n",
      "False Negative Rate total fair: 0.4409540430482839, for males: 0.42324786324786323, and for females: 0.5419103313840156\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8457286061767524\n",
      "C = 0.9385494213901379\n",
      "False Negative Rate total: 0.4098312972658522, for males: 0.39179487179487177, and for females: 0.5126705653021443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 15 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.232 \t fair_violation : 0.057 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.233 \t fair_violation : 0.070 \n",
      "accuracy: 0.8452126483378787\n",
      "C = 0.9499963145868652\n",
      "False Negative Rate total fair: 0.41084585912172117, for males: 0.3899546564352982, and for females: 0.5247148288973384\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8475713127441586\n",
      "C = 0.9387410628731481\n",
      "False Negative Rate total: 0.3775419982316534, for males: 0.35856295779560515, and for females: 0.48098859315589354\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 16 ----------------------------------\n",
      "Train - predict_err : 0.157 \t expected_err : 0.233 \t fair_violation : 0.063 \n",
      "Test  - predict_err : 0.151 \t expected_err : 0.231 \t fair_violation : 0.049 \n",
      "accuracy: 0.849487727574261\n",
      "C = 0.9492960860912508\n",
      "False Negative Rate total fair: 0.41644483880508726, for males: 0.40174825174825174, and for females: 0.4971209213051823\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8501511019385273\n",
      "C = 0.9400235866440628\n",
      "False Negative Rate total: 0.3904170363797693, for males: 0.3758741258741259, and for females: 0.47024952015355087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 17 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.231 \t fair_violation : 0.066 \n",
      "Test  - predict_err : 0.157 \t expected_err : 0.232 \t fair_violation : 0.080 \n",
      "accuracy: 0.8434436500331687\n",
      "C = 0.94931082774379\n",
      "False Negative Rate total fair: 0.44303048239124, for males: 0.42006920415224913, and for females: 0.5787321063394683\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8460971474902337\n",
      "C = 0.9390580084027419\n",
      "False Negative Rate total: 0.4030778336786031, for males: 0.3837370242214533, and for females: 0.5173824130879345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 18 ----------------------------------\n",
      "Train - predict_err : 0.158 \t expected_err : 0.232 \t fair_violation : 0.066 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.231 \t fair_violation : 0.064 \n",
      "accuracy: 0.8472764796933736\n",
      "C = 0.9528414535269404\n",
      "False Negative Rate total fair: 0.4459776864357017, for males: 0.4295161851722938, and for females: 0.5347091932457786\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8506670597774011\n",
      "C = 0.9424191051816909\n",
      "False Negative Rate total: 0.399588960657663, for males: 0.3825269752871563, and for females: 0.4915572232645403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 19 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.233 \t fair_violation : 0.062 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.232 \t fair_violation : 0.050 \n",
      "accuracy: 0.8473501879560699\n",
      "C = 0.9520527751160905\n",
      "False Negative Rate total fair: 0.42224204579244723, for males: 0.41096841374522736, and for females: 0.4896265560165975\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8487506449472986\n",
      "C = 0.9401783739957249\n",
      "False Negative Rate total: 0.39250669045495096, for males: 0.383547379382159, and for females: 0.4460580912863071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 20 ----------------------------------\n",
      "Train - predict_err : 0.152 \t expected_err : 0.231 \t fair_violation : 0.064 \n",
      "Test  - predict_err : 0.163 \t expected_err : 0.236 \t fair_violation : 0.041 \n",
      "accuracy: 0.8371047394412914\n",
      "C = 0.9467089260706125\n",
      "False Negative Rate total fair: 0.43944738389182836, for males: 0.42910830201571576, and for females: 0.5031578947368421\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.842927692194295\n",
      "C = 0.9353136286577726\n",
      "False Negative Rate total: 0.40652557319223986, for males: 0.3969935087119918, and for females: 0.4652631578947368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import arff\n",
    "# from prepare_data import prepare_compas,prepare_IBM_adult, prepare_law\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# from fair_logloss import DP_fair_logloss_classifier, EOPP_fair_logloss_classifier, EODD_fair_logloss_classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def compute_error(Yhat,proba,Y):\n",
    "    err = 1 - np.sum(Yhat == Y) / Y.shape[0] \n",
    "    exp_zeroone = np.mean(np.where(Y == 1 , 1 - proba, proba))\n",
    "    return err, exp_zeroone\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataA,dataY,dataX,perm = prepare_IBM_adult()\n",
    "    dataset = \"adult\"\n",
    "    C = .005\n",
    "    criteria = 'eqopp'#sys.argv[2]\n",
    "    if criteria == 'dp':\n",
    "        h = DP_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)\n",
    "    elif criteria == 'eqopp':\n",
    "        h = EOPP_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)\n",
    "    elif criteria == 'eqodd':\n",
    "        h = EODD_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)    \n",
    "    else:\n",
    "        raise ValueError('Invalid second arg')\n",
    "    filename_tr = \"fairll_{}_{:.3f}_{}_tr.csv\".format(dataset,C,criteria)\n",
    "    filename_ts = \"fairll_{}_{:.3f}_{}_ts.csv\".format(dataset,C,criteria)\n",
    "    \n",
    "    # outfile_tr = open(filename_tr,\"w\")\n",
    "    # outfile_ts = open(filename_ts,\"w\")\n",
    "\n",
    "    for r in range(20):\n",
    "        order = perm[r,:]\n",
    "        tr_sz = int(np.floor(.7 * dataX.shape[0]))\n",
    "        tr_idx = order[:tr_sz]\n",
    "        ts_idx = order[tr_sz:]\n",
    "        tr_X = dataX.reindex(tr_idx)\n",
    "        ts_X = dataX.reindex(ts_idx)\n",
    "        \n",
    "        tr_A = dataA.reindex(tr_X.index)\n",
    "        ts_A = dataA.reindex(ts_X.index)\n",
    "        tr_Y = dataY.reindex(tr_X.index)\n",
    "        ts_Y = dataY.reindex(ts_X.index)\n",
    "        \n",
    "        # Comment out to not include A in features\n",
    "        tr_X = pd.concat([tr_X, tr_A], axis=1) \t\n",
    "        ts_X = pd.concat([ts_X, ts_A], axis=1)\n",
    "        # ---------\n",
    "\n",
    "        for c in list(tr_X.columns):\n",
    "            if tr_X[c].min() < 0 or tr_X[c].max() > 1:\n",
    "                mu = tr_X[c].mean()\n",
    "                s = tr_X[c].std(ddof=0)\n",
    "                tr_X.loc[:,c] = (tr_X[c] - mu) / s\n",
    "                ts_X.loc[:,c] = (ts_X[c] - mu) / s\n",
    "        \n",
    "        h.fit(tr_X.values,tr_Y.values,tr_A.values)\n",
    "        exp_zo_tr = h.expected_error(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        exp_zo_ts = h.expected_error(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        err_tr = 1 - h.score(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        err_ts = 1 - h.score(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        violation_tr = h.fairness_violation(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        violation_ts = h.fairness_violation(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        prediction = h.predict(ts_X.values, ts_A.values)\n",
    "\n",
    "        # calculate consistency measure \n",
    "        # we use sklearn to find the nearest neighbors\n",
    "        neigh = NearestNeighbors(n_neighbors=11) # the first neighbour is always the data itself, therefore take 11 neighbours\n",
    "        nbrs = neigh.fit(ts_X.values)\n",
    "        distances, indices = nbrs.kneighbors(ts_X.values)\n",
    "        # calculate C\n",
    "        sum = 0\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(11):\n",
    "                sum += np.abs(int(prediction[i])-int(prediction[indices[i][j]]))\n",
    "        result = 1 - sum*(1/(10*len(indices)))\n",
    "        \n",
    "        total_FNR_fair,m_FNR_fair,f_FNR_fair = fairness_metrics(ts_Y.values,prediction,ts_A)\n",
    "        # train logistic regression \n",
    "        clf = LogisticRegression(random_state=0).fit(tr_X.values, tr_Y.values)\n",
    "        logistic_prediction = clf.predict(ts_X.values)\n",
    "        # calculate C\n",
    "        sum = 0\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(11):\n",
    "                sum += np.abs(int(logistic_prediction[i])-int(logistic_prediction[indices[i][j]]))\n",
    "        result_logistic_regression = 1 - sum*(1/(10*len(indices)))\n",
    "        \n",
    "        total_FNR,m_FNR,f_FNR = fairness_metrics(ts_Y.values,logistic_prediction,ts_A)\n",
    "        \n",
    "        print(\"---------------------------- Random Split %d ----------------------------------\" % (r + 1))\n",
    "        print(\"Train - predict_err : {:.3f} \\t expected_err : {:.3f} \\t fair_violation : {:.3f} \".format(err_tr, exp_zo_tr,violation_tr))\n",
    "        print(\"Test  - predict_err : {:.3f} \\t expected_err : {:.3f} \\t fair_violation : {:.3f} \".format(err_ts, exp_zo_ts,violation_ts))\n",
    "        print(\"accuracy:\", accuracy_score(ts_Y.values, prediction))\n",
    "        print(\"C =\",result)\n",
    "        print(\"False Negative Rate total fair: {}, for males: {}, and for females: {}\".format(total_FNR_fair,m_FNR_fair,f_FNR_fair))\n",
    "        print(\"for non-fair logistic regression:\")\n",
    "        print(\"accuracy:\", accuracy_score(ts_Y.values, logistic_prediction))\n",
    "        print(\"C =\",result_logistic_regression)\n",
    "        print(\"False Negative Rate total: {}, for males: {}, and for females: {}\".format(total_FNR,m_FNR,f_FNR))\n",
    "        print(\"\")\n",
    "\n",
    "    #     outfile_ts.write(\"{:.4f},{:.4f},{:.4f}\\n\".format(exp_zo_ts,err_ts, violation_ts))\n",
    "    #     outfile_tr.write(\"{:.4f},{:.4f},{:.4f}\\n\".format(exp_zo_tr,err_tr, violation_tr))\n",
    "        \n",
    "    # outfile_tr.close()\n",
    "    # outfile_ts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 1 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.252 \t fair_violation : 0.012 \n",
      "Test  - predict_err : 0.159 \t expected_err : 0.253 \t fair_violation : 0.025 \n",
      "accuracy: 0.8410849856268888\n",
      "C = 0.9479398540576398\n",
      "False Negative Rate total Fair: 0.4464759657918018, for males: 0.43840330350997936, and for females: 0.4948453608247423\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8438858996093462\n",
      "C = 0.9390285250976634\n",
      "False Negative Rate total: 0.4093187850191684, for males: 0.39298004129387476, and for females: 0.5072164948453608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 2 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.258 \t fair_violation : 0.020 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.257 \t fair_violation : 0.015 \n",
      "accuracy: 0.8464656888037149\n",
      "C = 0.9477113584432815\n",
      "False Negative Rate total Fair: 0.44132886315147823, for males: 0.4367897727272727, and for females: 0.46881720430107526\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.850372226726616\n",
      "C = 0.9393896955848751\n",
      "False Negative Rate total: 0.3940871685461749, for males: 0.3817471590909091, and for females: 0.46881720430107526\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 3 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.260 \t fair_violation : 0.036 \n",
      "Test  - predict_err : 0.157 \t expected_err : 0.261 \t fair_violation : 0.029 \n",
      "accuracy: 0.8427065674062062\n",
      "C = 0.9476597626593941\n",
      "False Negative Rate total Fair: 0.4584956547797423, for males: 0.45118920837770676, and for females: 0.4980769230769231\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8463919805410186\n",
      "C = 0.9366108940812266\n",
      "False Negative Rate total: 0.3928678453700929, for males: 0.3801916932907348, and for females: 0.46153846153846156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 4 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.259 \t fair_violation : 0.027 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.260 \t fair_violation : 0.010 \n",
      "accuracy: 0.8443281491855237\n",
      "C = 0.9450578609862166\n",
      "False Negative Rate total Fair: 0.4405657538368944, for males: 0.44189332391381136, and for females: 0.4329268292682927\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8470553549052848\n",
      "C = 0.9393159873221788\n",
      "False Negative Rate total: 0.399939813421607, for males: 0.39279406570116565, and for females: 0.4410569105691057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 5 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.258 \t fair_violation : 0.028 \n",
      "Test  - predict_err : 0.158 \t expected_err : 0.260 \t fair_violation : 0.042 \n",
      "accuracy: 0.8416746517284588\n",
      "C = 0.944438711579568\n",
      "False Negative Rate total Fair: 0.42237511217469337, for males: 0.41366024518388794, and for females: 0.4733606557377049\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8427065674062062\n",
      "C = 0.934539691899462\n",
      "False Negative Rate total: 0.39126533054142987, for males: 0.37583187390542905, and for females: 0.48155737704918034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 6 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.256 \t fair_violation : 0.024 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.254 \t fair_violation : 0.034 \n",
      "accuracy: 0.8450652318124862\n",
      "C = 0.9473207046509914\n",
      "False Negative Rate total Fair: 0.44610778443113774, for males: 0.4374331550802139, and for females: 0.491588785046729\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8468342301171962\n",
      "C = 0.9396624161568512\n",
      "False Negative Rate total: 0.3991017964071856, for males: 0.3775401069518717, and for females: 0.5121495327102804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 7 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.260 \t fair_violation : 0.032 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.260 \t fair_violation : 0.033 \n",
      "accuracy: 0.8455811896513599\n",
      "C = 0.9449620402447114\n",
      "False Negative Rate total Fair: 0.41789722386296513, for males: 0.40471997182106373, and for females: 0.48628884826325414\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8500036854131348\n",
      "C = 0.9374880224073119\n",
      "False Negative Rate total: 0.37950383933845244, for males: 0.35963367382881295, and for females: 0.4826325411334552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 8 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.258 \t fair_violation : 0.007 \n",
      "Test  - predict_err : 0.153 \t expected_err : 0.255 \t fair_violation : 0.014 \n",
      "accuracy: 0.8466868135918036\n",
      "C = 0.9490454779980836\n",
      "False Negative Rate total Fair: 0.4375930890676199, for males: 0.4399717514124294, and for females: 0.4247619047619048\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8491191862607799\n",
      "C = 0.9418957765165475\n",
      "False Negative Rate total: 0.4009532320524278, for males: 0.3866525423728814, and for females: 0.4780952380952381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 9 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.258 \t fair_violation : 0.018 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.257 \t fair_violation : 0.009 \n",
      "accuracy: 0.8456548979140561\n",
      "C = 0.9435394707746738\n",
      "False Negative Rate total Fair: 0.4304635761589404, for males: 0.42318634423897583, and for females: 0.47058823529411764\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8479398540576398\n",
      "C = 0.9366551190388442\n",
      "False Negative Rate total: 0.3798916315472607, for males: 0.3630867709815078, and for females: 0.4725490196078431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 10 ----------------------------------\n",
      "Train - predict_err : 0.153 \t expected_err : 0.253 \t fair_violation : 0.006 \n",
      "Test  - predict_err : 0.160 \t expected_err : 0.257 \t fair_violation : 0.011 \n",
      "accuracy: 0.839979361686445\n",
      "C = 0.9483599911550085\n",
      "False Negative Rate total Fair: 0.4532181168057211, for males: 0.45145631067961167, and for females: 0.4639830508474576\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8445492739736125\n",
      "C = 0.9402668239109604\n",
      "False Negative Rate total: 0.4028605482717521, for males: 0.3907766990291262, and for females: 0.4766949152542373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 11 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.261 \t fair_violation : 0.023 \n",
      "Test  - predict_err : 0.152 \t expected_err : 0.259 \t fair_violation : 0.046 \n",
      "accuracy: 0.8476450210068549\n",
      "C = 0.9454853689098548\n",
      "False Negative Rate total Fair: 0.4187003822405175, for males: 0.40563767617738056, and for females: 0.4959349593495935\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8504459349893123\n",
      "C = 0.9394781455001106\n",
      "False Negative Rate total: 0.37959423698912087, for males: 0.36094877964936406, and for females: 0.4898373983739837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 12 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.251 \t fair_violation : 0.015 \n",
      "Test  - predict_err : 0.157 \t expected_err : 0.252 \t fair_violation : 0.012 \n",
      "accuracy: 0.84322252524508\n",
      "C = 0.94774084174836\n",
      "False Negative Rate total Fair: 0.4572713643178411, for males: 0.45508356545961004, and for females: 0.4708423326133909\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8483083953711211\n",
      "C = 0.9399646200339058\n",
      "False Negative Rate total: 0.4047976011994003, for males: 0.3906685236768802, and for females: 0.4924406047516199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 13 ----------------------------------\n",
      "Train - predict_err : 0.157 \t expected_err : 0.245 \t fair_violation : 0.002 \n",
      "Test  - predict_err : 0.158 \t expected_err : 0.247 \t fair_violation : 0.018 \n",
      "accuracy: 0.8418220682538513\n",
      "C = 0.9549568806663227\n",
      "False Negative Rate total Fair: 0.4729336437718277, for males: 0.4728390843867441, and for females: 0.47347740667976423\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8469816466425887\n",
      "C = 0.9388147711358443\n",
      "False Negative Rate total: 0.39726426076833526, for males: 0.38435257943286644, and for females: 0.4715127701375246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 14 ----------------------------------\n",
      "Train - predict_err : 0.155 \t expected_err : 0.260 \t fair_violation : 0.040 \n",
      "Test  - predict_err : 0.159 \t expected_err : 0.263 \t fair_violation : 0.037 \n",
      "accuracy: 0.8413798186776738\n",
      "C = 0.9478661457949437\n",
      "False Negative Rate total Fair: 0.4569517161140198, for males: 0.4454700854700855, and for females: 0.5224171539961013\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8457286061767524\n",
      "C = 0.9385494213901379\n",
      "False Negative Rate total: 0.4098312972658522, for males: 0.39179487179487177, and for females: 0.5126705653021443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 15 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.263 \t fair_violation : 0.035 \n",
      "Test  - predict_err : 0.155 \t expected_err : 0.264 \t fair_violation : 0.048 \n",
      "accuracy: 0.8450652318124862\n",
      "C = 0.9503280017689983\n",
      "False Negative Rate total Fair: 0.412614205717654, for males: 0.39518660620858037, and for females: 0.5076045627376425\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8475713127441586\n",
      "C = 0.9387410628731481\n",
      "False Negative Rate total: 0.3775419982316534, for males: 0.35856295779560515, and for females: 0.48098859315589354\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 16 ----------------------------------\n",
      "Train - predict_err : 0.157 \t expected_err : 0.262 \t fair_violation : 0.038 \n",
      "Test  - predict_err : 0.149 \t expected_err : 0.260 \t fair_violation : 0.036 \n",
      "accuracy: 0.8505196432520086\n",
      "C = 0.9480651581042234\n",
      "False Negative Rate total Fair: 0.41821946169772256, for males: 0.40664335664335666, and for females: 0.4817658349328215\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8501511019385273\n",
      "C = 0.9400235866440628\n",
      "False Negative Rate total: 0.3904170363797693, for males: 0.3758741258741259, and for females: 0.47024952015355087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 17 ----------------------------------\n",
      "Train - predict_err : 0.154 \t expected_err : 0.260 \t fair_violation : 0.026 \n",
      "Test  - predict_err : 0.156 \t expected_err : 0.262 \t fair_violation : 0.040 \n",
      "accuracy: 0.8443281491855237\n",
      "C = 0.94990049384536\n",
      "False Negative Rate total Fair: 0.4374075170168689, for males: 0.42387543252595156, and for females: 0.5173824130879345\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8460971474902337\n",
      "C = 0.9390580084027419\n",
      "False Negative Rate total: 0.4030778336786031, for males: 0.3837370242214533, and for females: 0.5173824130879345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 18 ----------------------------------\n",
      "Train - predict_err : 0.158 \t expected_err : 0.256 \t fair_violation : 0.022 \n",
      "Test  - predict_err : 0.154 \t expected_err : 0.254 \t fair_violation : 0.016 \n",
      "accuracy: 0.8463182722783223\n",
      "C = 0.9466499594604555\n",
      "False Negative Rate total Fair: 0.43305930710510865, for males: 0.4291681169509224, and for females: 0.4540337711069418\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8506670597774011\n",
      "C = 0.9424191051816909\n",
      "False Negative Rate total: 0.399588960657663, for males: 0.3825269752871563, and for females: 0.4915572232645403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 19 ----------------------------------\n",
      "Train - predict_err : 0.156 \t expected_err : 0.263 \t fair_violation : 0.033 \n",
      "Test  - predict_err : 0.152 \t expected_err : 0.263 \t fair_violation : 0.021 \n",
      "accuracy: 0.8476450210068549\n",
      "C = 0.9496793690572713\n",
      "False Negative Rate total Fair: 0.42521558132619686, for males: 0.41895175286358904, and for females: 0.46265560165975106\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.8487506449472986\n",
      "C = 0.9401783739957249\n",
      "False Negative Rate total: 0.39250669045495096, for males: 0.383547379382159, and for females: 0.4460580912863071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srodriguezb\\Anaconda3\\envs\\introds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Random Split 20 ----------------------------------\n",
      "Train - predict_err : 0.151 \t expected_err : 0.255 \t fair_violation : 0.029 \n",
      "Test  - predict_err : 0.163 \t expected_err : 0.260 \t fair_violation : 0.009 \n",
      "accuracy: 0.8365150733397214\n",
      "C = 0.9431488169823837\n",
      "False Negative Rate total Fair: 0.44238683127572015, for males: 0.43969935087119916, and for females: 0.4589473684210526\n",
      "for non-fair logistic regression:\n",
      "accuracy: 0.842927692194295\n",
      "C = 0.9353136286577726\n",
      "False Negative Rate total: 0.40652557319223986, for males: 0.3969935087119918, and for females: 0.4652631578947368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import arff\n",
    "# from prepare_data import prepare_compas,prepare_IBM_adult, prepare_law\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# from fair_logloss import DP_fair_logloss_classifier, EOPP_fair_logloss_classifier, EODD_fair_logloss_classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def compute_error(Yhat,proba,Y):\n",
    "    err = 1 - np.sum(Yhat == Y) / Y.shape[0] \n",
    "    exp_zeroone = np.mean(np.where(Y == 1 , 1 - proba, proba))\n",
    "    return err, exp_zeroone\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataA,dataY,dataX,perm = prepare_IBM_adult()\n",
    "    dataset = \"adult\"\n",
    "    C = .005\n",
    "    criteria = 'eqodd'#sys.argv[2]\n",
    "    if criteria == 'dp':\n",
    "        h = DP_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)\n",
    "    elif criteria == 'eqopp':\n",
    "        h = EOPP_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)\n",
    "    elif criteria == 'eqodd':\n",
    "        h = EODD_fair_logloss_classifier(C=C, random_initialization=True, verbose=False)    \n",
    "    else:\n",
    "        raise ValueError('Invalid second arg')\n",
    "    filename_tr = \"fairll_{}_{:.3f}_{}_tr.csv\".format(dataset,C,criteria)\n",
    "    filename_ts = \"fairll_{}_{:.3f}_{}_ts.csv\".format(dataset,C,criteria)\n",
    "    \n",
    "    # outfile_tr = open(filename_tr,\"w\")\n",
    "    # outfile_ts = open(filename_ts,\"w\")\n",
    "\n",
    "    for r in range(20):\n",
    "        order = perm[r,:]\n",
    "        tr_sz = int(np.floor(.7 * dataX.shape[0]))\n",
    "        tr_idx = order[:tr_sz]\n",
    "        ts_idx = order[tr_sz:]\n",
    "        tr_X = dataX.reindex(tr_idx)\n",
    "        ts_X = dataX.reindex(ts_idx)\n",
    "        \n",
    "        tr_A = dataA.reindex(tr_X.index)\n",
    "        ts_A = dataA.reindex(ts_X.index)\n",
    "        tr_Y = dataY.reindex(tr_X.index)\n",
    "        ts_Y = dataY.reindex(ts_X.index)\n",
    "        \n",
    "        # Comment out to not include A in features\n",
    "        tr_X = pd.concat([tr_X, tr_A], axis=1) \t\n",
    "        ts_X = pd.concat([ts_X, ts_A], axis=1)\n",
    "        # ---------\n",
    "\n",
    "        for c in list(tr_X.columns):\n",
    "            if tr_X[c].min() < 0 or tr_X[c].max() > 1:\n",
    "                mu = tr_X[c].mean()\n",
    "                s = tr_X[c].std(ddof=0)\n",
    "                tr_X.loc[:,c] = (tr_X[c] - mu) / s\n",
    "                ts_X.loc[:,c] = (ts_X[c] - mu) / s\n",
    "        \n",
    "        h.fit(tr_X.values,tr_Y.values,tr_A.values)\n",
    "        exp_zo_tr = h.expected_error(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        exp_zo_ts = h.expected_error(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        err_tr = 1 - h.score(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        err_ts = 1 - h.score(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        violation_tr = h.fairness_violation(tr_X.values, tr_Y.values, tr_A.values)\n",
    "        violation_ts = h.fairness_violation(ts_X.values, ts_Y.values, ts_A.values)\n",
    "        prediction = h.predict(ts_X.values, ts_A.values)\n",
    "\n",
    "        # calculate consistency measure \n",
    "        # we use sklearn to find the nearest neighbors\n",
    "        neigh = NearestNeighbors(n_neighbors=11) # the first neighbour is always the data itself, therefore take 11 neighbours\n",
    "        nbrs = neigh.fit(ts_X.values)\n",
    "        distances, indices = nbrs.kneighbors(ts_X.values)\n",
    "        # calculate C\n",
    "        sum = 0\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(11):\n",
    "                sum += np.abs(int(prediction[i])-int(prediction[indices[i][j]]))\n",
    "        result = 1 - sum*(1/(10*len(indices)))\n",
    "        \n",
    "        total_FNR_fair,m_FNR_fair,f_FNR_fair = fairness_metrics(ts_Y.values,prediction,ts_A)\n",
    "        # train logistic regression \n",
    "        clf = LogisticRegression(random_state=0).fit(tr_X.values, tr_Y.values)\n",
    "        logistic_prediction = clf.predict(ts_X.values)\n",
    "        # calculate C\n",
    "        sum = 0\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(11):\n",
    "                sum += np.abs(int(logistic_prediction[i])-int(logistic_prediction[indices[i][j]]))\n",
    "        result_logistic_regression = 1 - sum*(1/(10*len(indices)))\n",
    "        \n",
    "        total_FNR,m_FNR,f_FNR = fairness_metrics(ts_Y.values,logistic_prediction,ts_A)\n",
    "        \n",
    "        print(\"---------------------------- Random Split %d ----------------------------------\" % (r + 1))\n",
    "        print(\"Train - predict_err : {:.3f} \\t expected_err : {:.3f} \\t fair_violation : {:.3f} \".format(err_tr, exp_zo_tr,violation_tr))\n",
    "        print(\"Test  - predict_err : {:.3f} \\t expected_err : {:.3f} \\t fair_violation : {:.3f} \".format(err_ts, exp_zo_ts,violation_ts))\n",
    "        print(\"accuracy:\", accuracy_score(ts_Y.values, prediction))\n",
    "        print(\"C =\",result)\n",
    "        print(\"False Negative Rate total Fair: {}, for males: {}, and for females: {}\".format(total_FNR_fair,m_FNR_fair,f_FNR_fair))\n",
    "        print(\"for non-fair logistic regression:\")\n",
    "        print(\"accuracy:\", accuracy_score(ts_Y.values, logistic_prediction))\n",
    "        print(\"C =\",result_logistic_regression)\n",
    "        print(\"False Negative Rate total: {}, for males: {}, and for females: {}\".format(total_FNR,m_FNR,f_FNR))\n",
    "        print(\"\")\n",
    "\n",
    "    #     outfile_ts.write(\"{:.4f},{:.4f},{:.4f}\\n\".format(exp_zo_ts,err_ts, violation_ts))\n",
    "    #     outfile_tr.write(\"{:.4f},{:.4f},{:.4f}\\n\".format(exp_zo_tr,err_tr, violation_tr))\n",
    "        \n",
    "    # outfile_tr.close()\n",
    "    # outfile_ts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "48e4fac23f847e31e50a977181370ac78afc4be9236ebe86c805f672a975b811"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
